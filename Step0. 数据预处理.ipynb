{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488711bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import pandas as pd\n",
    "from onekey_algo import get_param_in_cwd\n",
    "\n",
    "data_root = get_param_in_cwd('data_root')\n",
    "label_data = pd.read_csv(os.path.join(data_root, 'label.csv'))\n",
    "label_data['label'] = label_data['EGFR突变状态'].map(lambda x: 1 if '有' in x else 0)\n",
    "label_data['ID'] = label_data['姓名'].map(lambda x: x.strip().replace(' ', ''))\n",
    "label_data = label_data.drop_duplicates('ID').sort_values('ID')\n",
    "label_data[['ID', 'label']].to_csv(os.path.join(get_param_in_cwd('data_root'), 'label_rmdup.csv'), index=False, encoding='utf-8-sig')\n",
    "label_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d41404",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "patches_root = os.path.join(data_root, 'Pathology', 'patches')\n",
    "sample_mapping = {}\n",
    "for sample in os.listdir(patches_root):\n",
    "    if not os.path.isdir(os.path.join(patches_root, sample)):\n",
    "        continue\n",
    "    if ' ' in sample:\n",
    "        nsample = sample.split(' ')[0]\n",
    "    else:\n",
    "        nsample = re.sub(r'\\d+', '', sample)\n",
    "    sample_mapping[sample] = nsample\n",
    "    \n",
    "# if len(set(sample_mapping.values()) - set(label_data['ID'])) == 0:\n",
    "#     for k, v in sample_mapping.items():\n",
    "#         shutil.move(os.path.join(patches_root, k), os.path.join(patches_root, v))\n",
    "\n",
    "# pd.DataFrame(sample_mapping.items(), columns=['ori', 'mapping']).to_csv(os.path.join(data_root, 'path_mapping.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38983030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "radio_dir = os.path.join(data_root, 'Radiology', 'nii', 'both')\n",
    "image_dir = os.path.join(data_root, 'Radiology', 'images')\n",
    "masks_dir = os.path.join(data_root, 'Radiology', 'masks')\n",
    "for sample in os.listdir(radio_dir):\n",
    "    if os.path.exists(os.path.join(image_dir, f\"{sample}.nii.gz\")):\n",
    "        continue\n",
    "    images = sorted(glob(os.path.join(radio_dir, sample, '*.nii.gz')))\n",
    "    masks = sorted(glob(os.path.join(radio_dir, sample, '*', '*.nii.gz')))\n",
    "    has = False\n",
    "    for i, m in zip(images, masks):\n",
    "        iarr = np.array(nib.load(i).dataobj)\n",
    "        marr = np.array(nib.load(m).dataobj)\n",
    "        if iarr.shape == marr.shape:\n",
    "            has = True\n",
    "            shutil.copy(i, os.path.join(image_dir, f\"{sample}.nii.gz\"))\n",
    "            shutil.copy(m, os.path.join(masks_dir, f\"{sample}.nii.gz\"))\n",
    "            break\n",
    "    if not has:\n",
    "        print(sample, 'Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc5ddaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from onekey_algo.custom.components.Radiology import get_image_mask_from_dir, diagnose_3d_image_mask_settings\n",
    "\n",
    "ims, mss = get_image_mask_from_dir(os.path.join(data_root, 'Radiology'), 'images', 'masks')\n",
    "info = diagnose_3d_image_mask_settings(ims, mss, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf65d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "set(label_data['ID']) - set(map(lambda x: x.replace('.nii.gz', ''), os.listdir(masks_dir))) - set(os.listdir(patches_root))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af31d46c",
   "metadata": {},
   "source": [
    "# 划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd989612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from onekey_algo.custom.components.comp2 import split_dataset4sol\n",
    "from onekey_algo import get_param_in_cwd\n",
    "\n",
    "root = get_param_in_cwd('data_root')\n",
    "label_data = pd.read_csv(os.path.join(root, 'label_rmdup.csv'))\n",
    "\n",
    "patches = pd.DataFrame(glob(os.path.join(root, 'Pathology', 'patches', '*', '*.jpg')), columns=['fpath'])\n",
    "patches['ID'] = patches['fpath'].map(lambda x: os.path.basename(os.path.dirname(x)))\n",
    "patches['filename'] = patches['fpath'].map(lambda x: os.path.basename(x))\n",
    "patches                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcda8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from onekey_algo.custom.components.comp2 import split_dataset4sol\n",
    "from onekey_algo import get_param_in_cwd      \n",
    "\n",
    "ds = split_dataset4sol(label_data, y_data=label_data['label'], n_trails=5, save_dir=os.path.join(root), \n",
    "                       random_state=0, cv=False, test_size=0.3, map_ext='.nii.gz')\n",
    "\n",
    "for idx, (train, val) in enumerate(ds):\n",
    "    train = pd.merge(train, patches[['ID', 'fpath']], on='ID', how='inner')\n",
    "    train[['fpath', 'label']].to_csv(os.path.join(root, 'split_info', f'Path_train-RND-{idx}.txt'), index=False, header=False, sep='\\t')\n",
    "    val = pd.merge(val, patches[['ID', 'fpath']], on='ID', how='inner')\n",
    "    val[['fpath', 'label']].to_csv(os.path.join(root, 'split_info', f'Path_val-RND-{idx}.txt'), index=False, header=False, sep='\\t')\n",
    "    print(f\"随机划分：{idx}，训练集：{train.shape[0]}, {len(np.unique(train['ID']))}, 测试集集：{val.shape[0]}, {len(np.unique(val['ID']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ba10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# path_group = pd.read_csv('Pathology/group.csv')\n",
    "# path_group['ID'] = path_group['ID'].map(lambda x: f\"{x}.nii.gz\")\n",
    "# rad_group = pd.read_csv('group.csv')\n",
    "# group = pd.concat([path_group, rad_group], axis=0).drop_duplicates('ID')\n",
    "# print(group['group'].value_counts())\n",
    "# group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942b19a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
